{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHO Fitter on the noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from src.m3_learning.optimizers.AdaHessian import AdaHessian\n",
    "from src.m3_learning.nn.SHO_fitter.SHO import SHO_fit_func_torch\n",
    "from src.m3_learning.be.processing import convert_amp_phase, SHO_Fitter\n",
    "from src.m3_learning.nn.random import random_seed\n",
    "from src.m3_learning.util.preprocessing import global_scaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets path to file\n",
    "path = r\"./\"\n",
    "\n",
    "# Opens the data file\n",
    "h5_f = h5py.File(path + \"data_file.h5\", \"r+\")\n",
    "\n",
    "# number of pixels in the image\n",
    "num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "\n",
    "num_pix_1d = int(np.sqrt(num_pix))\n",
    "\n",
    "# Frequency Vector in Hz\n",
    "frequency_bin = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Bin_Frequencies\"][:]\n",
    "\n",
    "# extracting spectroscopic values\n",
    "spectroscopic_values = h5_f['Measurement_000']['Channel_000']['Spectroscopic_Values']\n",
    "\n",
    "# number of DC voltage steps\n",
    "voltage_steps = h5_f[\"Measurement_000\"].attrs[\"num_udvs_steps\"]\n",
    "\n",
    "# Resampled frequency vector\n",
    "wvec_freq = resample(frequency_bin, 80)\n",
    "\n",
    "# get raw data (real and imaginary combined)\n",
    "raw_data = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]\n",
    "raw_data_resampled = resample(np.array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]).reshape(-1, 165), 80, axis=1)\n",
    "\n",
    "# conversion of raw data (both resampled and full)\n",
    "amp, phase = convert_amp_phase(raw_data)\n",
    "amp_resample, phase_resample = convert_amp_phase(raw_data_resampled)\n",
    "\n",
    "scaled_data = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['scaled_data'][:]\n",
    "real_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['real_resample'][:]\n",
    "imag_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['imag_resample'][:]\n",
    "\n",
    "# scale the real component of input data\n",
    "scaler_real = global_scaler()\n",
    "scaled_data_real = scaler_real.fit_transform(real_resample).reshape(-1, 80)\n",
    "\n",
    "# scale the imaginary component of input data\n",
    "scaler_imag = global_scaler()\n",
    "scaled_data_imag = scaler_imag.fit_transform(imag_resample).reshape(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO extract fit params\n",
    "\n",
    "# create a list for parameters\n",
    "fit_results_list = []\n",
    "for sublist in np.array(\n",
    "    h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-SHO_Fit_000\"][\"Fit\"]\n",
    "):\n",
    "    for item in sublist:\n",
    "        for i in item:\n",
    "            fit_results_list.append(i)\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "fit_results_list = np.array(fit_results_list).reshape(num_pix, voltage_steps, 5)\n",
    "\n",
    "# exclude the R2 parameter\n",
    "params = fit_results_list.reshape(-1, 5)[:, 0:4]\n",
    "\n",
    "# scale the parameters (now takes only 4 parameters, excluding the R2)\n",
    "params_scaler = StandardScaler()\n",
    "scaled_params = params_scaler.fit_transform(fit_results_list.reshape(-1, 5)[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_noise_real = -1.0 * 0.0026878386 # 2.6e-3\n",
    "highest_noise_real = 1.0 * 0.0026878386\n",
    "lowest_noise_imag = -1.0 * 0.0027575183\n",
    "highest_noise_imag = 1.0 * 0.0027575183\n",
    "\n",
    "noise_real = np.random.uniform(lowest_noise_real, highest_noise_real, (3600, 63360))\n",
    "noise_imag = np.random.uniform(lowest_noise_imag, highest_noise_imag, (3600, 63360))\n",
    "noise = noise_real+noise_imag*1.0j\n",
    "\n",
    "noise_levels = ['2.0', '4.0', '7.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all computations were pre-computed on A100 40GB NHI GPU\n",
    "# set to False if you want to recompute\n",
    "use_pre_computed_vars = False\n",
    "use_pre_trained_models = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copies initial dataset for the later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_computed_vars:\n",
    "  # close the current file to perform a copy\n",
    "  h5_f.close()\n",
    "  for nl in noise_levels:\n",
    "    shutil.copy('data_file.h5', f'data_file_noise_{nl}.h5')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level in noise_levels:\n",
    "  h5_f_noise = h5py.File(f'./data_file_noise_{noise_level}.h5', 'r+')\n",
    "  time.sleep(5)\n",
    "  raw_data_noise = h5_f_noise['Measurement_000']['Channel_000']['Raw_Data']\n",
    "  noise_level_float = float(noise_level)\n",
    "\n",
    "  for pixel_ind, pixel_data in enumerate(raw_data_noise):\n",
    "    raw_data_noise[pixel_ind] += noise[pixel_ind] * noise_level_float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builds the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHO_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input block of 1d convolution\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # fully connected block\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 20),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # 2nd block of 1d-conv layers\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        # Final embedding block - Output 4 values - linear\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(26, 16),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(8, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "        x = torch.swapaxes(x, 1, 2)  # output shape - samples, (real, imag), frequency\n",
    "        x = self.hidden_x1(x)\n",
    "        xfc = torch.reshape(x, (n, 256))  # batch size, features\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "        x = torch.reshape(x, (n, 2, 128))  # batch size, (real, imag), timesteps\n",
    "        x = self.hidden_x2(x)\n",
    "        cnn_flat = self.flatten_layer(x)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)  # merge dense and 1d conv.\n",
    "        embedding = self.hidden_embedding(encoded)  # output is 4 parameters\n",
    "\n",
    "        # corrects the scaling of the parameters\n",
    "        unscaled_param = (\n",
    "            embedding * torch.tensor(params_scaler.var_[0:4] ** 0.5).cuda()\n",
    "            + torch.tensor(params_scaler.mean_[0:4]).cuda()\n",
    "        )\n",
    "\n",
    "        # passes to the pytorch fitting function\n",
    "        fits = SHO_fit_func_torch(unscaled_param, wvec_freq, device=\"cuda\")\n",
    "\n",
    "        # extract and return real and imaginary\n",
    "        real = torch.real(fits)\n",
    "        real_scaled = (real - torch.tensor(scaler_real.mean).cuda()) / torch.tensor(\n",
    "            scaler_real.std\n",
    "        ).cuda()\n",
    "        imag = torch.imag(fits)\n",
    "        imag_scaled = (imag - torch.tensor(scaler_imag.mean).cuda()) / torch.tensor(\n",
    "            scaler_imag.std\n",
    "        ).cuda()\n",
    "        out = torch.stack((real_scaled, imag_scaled), 2)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, params_train, params_test = train_test_split(\n",
    "    scaled_data, scaled_params, test_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "params_test_unscaled = params_scaler.inverse_transform(params_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_trained_models:\n",
    "  max_num_of_updates = scaled_data.shape[0] // 16 * 10\n",
    "  output_tensor_dict = {}\n",
    "  seed = 0\n",
    "  noise_reshaped = resample(noise.reshape(-1, 165), 80, axis=1)\n",
    "  noise_2d = np.stack((np.real(noise_reshaped), np.imag(noise_reshaped)), axis=2)\n",
    "  noise_train, noise_test = train_test_split(noise_2d, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch seed was set to 42\n",
      "Numpy seed was set to 42\n",
      "tensorflow seed was set to 42\n",
      "Training with batch size = 128, noise factor = 2.0\n",
      "epoch : 1/5, recon loss = 0.06884452\n",
      "--- 145.76854062080383 seconds ---\n",
      "epoch : 2/5, recon loss = 0.04359256\n",
      "--- 137.72051239013672 seconds ---\n",
      "epoch : 3/5, recon loss = 0.04302800\n",
      "--- 139.86019277572632 seconds ---\n",
      "epoch : 4/5, recon loss = 0.04274226\n",
      "--- 135.64201617240906 seconds ---\n",
      "epoch : 5/5, recon loss = 0.04257585\n",
      "--- 138.4973783493042 seconds ---\n",
      "Training with batch size=128 took 697.4886403083801 seconds\n",
      "\n",
      "Pytorch seed was set to 42\n",
      "Numpy seed was set to 42\n",
      "tensorflow seed was set to 42\n",
      "Training with batch size = 128, noise factor = 4.0\n",
      "epoch : 1/5, recon loss = 0.06885658\n",
      "--- 131.4208345413208 seconds ---\n",
      "epoch : 2/5, recon loss = 0.04361876\n",
      "--- 131.48116183280945 seconds ---\n",
      "epoch : 3/5, recon loss = 0.04306932\n",
      "--- 134.61423778533936 seconds ---\n",
      "epoch : 4/5, recon loss = 0.04275457\n",
      "--- 143.55308771133423 seconds ---\n",
      "epoch : 5/5, recon loss = 0.04259585\n",
      "--- 139.84633350372314 seconds ---\n",
      "Training with batch size=128 took 680.9167721271515 seconds\n",
      "\n",
      "Pytorch seed was set to 42\n",
      "Numpy seed was set to 42\n",
      "tensorflow seed was set to 42\n",
      "Training with batch size = 128, noise factor = 7.0\n",
      "epoch : 1/5, recon loss = 0.06899062\n",
      "--- 138.4037914276123 seconds ---\n",
      "epoch : 2/5, recon loss = 0.04355663\n",
      "--- 147.0667507648468 seconds ---\n",
      "epoch : 3/5, recon loss = 0.04297300\n",
      "--- 137.9770336151123 seconds ---\n",
      "epoch : 4/5, recon loss = 0.04272235\n",
      "--- 131.67998099327087 seconds ---\n",
      "epoch : 5/5, recon loss = 0.04258582\n",
      "--- 169.39415311813354 seconds ---\n",
      "Training with batch size=128 took 724.5237331390381 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not use_pre_trained_models:\n",
    "  for noise_factor in noise_levels:\n",
    "      noise_factor = float(noise_factor)\n",
    "      random_seed(seed=42)\n",
    "      torch.cuda.empty_cache()\n",
    "      model = SHO_Model().cuda()\n",
    "\n",
    "      loss_func = torch.nn.MSELoss()\n",
    "      batch_size = 128\n",
    "      data_noise = scaled_data + noise_2d * noise_factor\n",
    "      data_train_noise = data_train + noise_train * noise_factor\n",
    "      data_test_noise = data_test + noise_test * noise_factor\n",
    "\n",
    "      optimizer = torch.optim.Adam(model.parameters())\n",
    "      train_dataloader = DataLoader(data_train_noise, batch_size=batch_size)\n",
    "      epochs = max_num_of_updates * batch_size // scaled_data.shape[0] // 16\n",
    "      print(f\"Training with batch size = {batch_size}, noise factor = {noise_factor}\")\n",
    "      start_time_training = time.time()\n",
    "      for epoch in range(epochs):\n",
    "          start_time = time.time()\n",
    "          train_loss = 0.\n",
    "          total_num = 0\n",
    "\n",
    "          model.train()\n",
    "\n",
    "          for train_batch in train_dataloader:\n",
    "              pred = model(train_batch.double().cuda())\n",
    "              optimizer.zero_grad()\n",
    "              loss = loss_func(train_batch.double().cuda(), pred)\n",
    "              loss.backward(create_graph=True)\n",
    "              train_loss += loss.item() * pred.shape[0]\n",
    "              total_num += pred.shape[0]\n",
    "              optimizer.step()\n",
    "\n",
    "          train_loss /= total_num\n",
    "          torch.save(model.state_dict(), f'./Trained Models/SHO Fitter/model_noise_{noise_factor}_bs128.pt')\n",
    "\n",
    "          print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs, train_loss))\n",
    "          print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "      print(f\"Training with batch size={batch_size} took {time.time() - start_time_training} seconds\\n\")\n",
    "\n",
    "      del train_dataloader\n",
    "      del data_noise\n",
    "      del data_train_noise\n",
    "      del data_test_noise\n",
    "      del model\n",
    "      gc.collect()\n",
    "      torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abeke\\anaconda3\\envs\\rapid_fitting\\lib\\site-packages\\sidpy\\sid\\translator.py:42: FutureWarning: Consider using sidpy.Reader instead of sidpy.Translator if possible and contribute your reader to ScopeReaders\n",
      "  warn('Consider using sidpy.Reader instead of sidpy.Translator if '\n",
      "c:\\Users\\abeke\\anaconda3\\envs\\rapid_fitting\\lib\\site-packages\\BGlib\\be\\translators\\labview_h5_patcher.py:132: UserWarning: 'channel_type' was not found as an attribute of /Measurement_000/Channel_000.\n",
      "If this is BEPS or BELine data from the LabView aquisition software, please run the following piece of code.  Afterwards, run this function again.\n",
      "CODE: hdf.file['/Measurement_000/Channel_000'].attrs['channel_type'] = 'BE'\n",
      "  warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:\n",
      "data_file_noise_2.0.h5\n",
      "['Y', 'X'] [60, 60]\n",
      "\n",
      "\n",
      "SHO Fits will be written to:\n",
      "data_file_noise_2.0.h5\n",
      "\n",
      "\n",
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes results to the HDF5 file\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000\n",
      "LSQF method took 9.753665924072266 seconds to compute parameters\n",
      "Computation for noise level=2.0 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abeke\\anaconda3\\envs\\rapid_fitting\\lib\\site-packages\\sidpy\\sid\\translator.py:42: FutureWarning: Consider using sidpy.Reader instead of sidpy.Translator if possible and contribute your reader to ScopeReaders\n",
      "  warn('Consider using sidpy.Reader instead of sidpy.Translator if '\n",
      "c:\\Users\\abeke\\anaconda3\\envs\\rapid_fitting\\lib\\site-packages\\BGlib\\be\\translators\\labview_h5_patcher.py:132: UserWarning: 'channel_type' was not found as an attribute of /Measurement_000/Channel_000.\n",
      "If this is BEPS or BELine data from the LabView aquisition software, please run the following piece of code.  Afterwards, run this function again.\n",
      "CODE: hdf.file['/Measurement_000/Channel_000'].attrs['channel_type'] = 'BE'\n",
      "  warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:\n",
      "data_file_noise_4.0.h5\n",
      "['Y', 'X'] [60, 60]\n",
      "\n",
      "\n",
      "SHO Fits will be written to:\n",
      "data_file_noise_4.0.h5\n",
      "\n",
      "\n",
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes results to the HDF5 file\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000\n",
      "LSQF method took 6.428034067153931 seconds to compute parameters\n",
      "Computation for noise level=4.0 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abeke\\anaconda3\\envs\\rapid_fitting\\lib\\site-packages\\sidpy\\sid\\translator.py:42: FutureWarning: Consider using sidpy.Reader instead of sidpy.Translator if possible and contribute your reader to ScopeReaders\n",
      "  warn('Consider using sidpy.Reader instead of sidpy.Translator if '\n",
      "c:\\Users\\abeke\\anaconda3\\envs\\rapid_fitting\\lib\\site-packages\\BGlib\\be\\translators\\labview_h5_patcher.py:132: UserWarning: 'channel_type' was not found as an attribute of /Measurement_000/Channel_000.\n",
      "If this is BEPS or BELine data from the LabView aquisition software, please run the following piece of code.  Afterwards, run this function again.\n",
      "CODE: hdf.file['/Measurement_000/Channel_000'].attrs['channel_type'] = 'BE'\n",
      "  warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:\n",
      "data_file_noise_7.0.h5\n",
      "['Y', 'X'] [60, 60]\n",
      "\n",
      "\n",
      "SHO Fits will be written to:\n",
      "data_file_noise_7.0.h5\n",
      "\n",
      "\n",
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes results to the HDF5 file\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000\n",
      "\n",
      "Note: SHO_Fit has already been performed PARTIALLY with the same parameters. compute() will resuming computation in the last group below. To choose a different group call use_patial_computation()Set override to True to force fresh computation or resume from a data group besides the last in the list.\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000\" (7 members)>]\n",
      "Resuming computation. 0% completed already\n",
      "\tThis class (likely) supports interruption and resuming of computations!\n",
      "\tIf you are operating in a python console, press Ctrl+C or Cmd+C to abort\n",
      "\tIf you are in a Jupyter notebook, click on \"Kernel\">>\"Interrupt\"\n",
      "\tIf you are operating on a cluster and your job gets killed, re-run the job to resume\n",
      "\n",
      "Rank 0 - 100% complete. Time remaining: 0.0 msec\n",
      "Finished processing the entire dataset!\n",
      "LSQF method took 802.4944143295288 seconds to compute parameters\n",
      "Computation for noise level=7.0 is done!\n"
     ]
    }
   ],
   "source": [
    "for noise_level in noise_levels:\n",
    "    SHO_Fitter(f'data_file_noise_{noise_level}.h5', force=True)\n",
    "    print(f'Computation for noise level={noise_level} is done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses Pre-computed Noisy SHO Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pre_computed_vars:\n",
    "  !unzip noisy_sho_fits.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid_fitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58f42fd11d8ae4df132d3c425059695e86ccc63a852aa66615442730ca8b1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
